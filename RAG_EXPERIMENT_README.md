# CoderEval RAG æ£€ç´¢å®éªŒæŒ‡å—

æœ¬æ–‡æ¡£æè¿°äº†ä½¿ç”¨ç¨€ç–æ£€ç´¢æ–¹æ³• (BM25 / Jaccard) è¿›è¡Œä»£ç ç”Ÿæˆä¸Šä¸‹æ–‡æ£€ç´¢å®éªŒçš„å®Œæ•´æµç¨‹ã€‚

## ğŸ“‹ å®éªŒæ¦‚è¿°

### ç›®æ ‡

è¯„ä¼°ä¸åŒç¨€ç–æ£€ç´¢æ–¹æ³•åœ¨ä¸åŒä¸Šä¸‹æ–‡é•¿åº¦ä¸‹å¯¹ä»£ç ç”Ÿæˆæ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

### æ£€ç´¢æ–¹æ³•

1. **BM25** - åŸºäºè¯é¢‘-é€†æ–‡æ¡£é¢‘ç‡çš„ç»å…¸æ£€ç´¢ç®—æ³•
2. **Jaccard** - åŸºäºé›†åˆç›¸ä¼¼åº¦çš„æ£€ç´¢ç®—æ³•

### ä¸Šä¸‹æ–‡é•¿åº¦

`1k, 2k, 4k, 8k, 16k, 32k, 64k, 128k, 192k` tokens

## ğŸ—‚ï¸ æ–‡ä»¶ç»“æ„

```
CoderEval Docker/
â”œâ”€â”€ sparse_retrieval_context.py    # ç¨€ç–æ£€ç´¢ä¸Šä¸‹æ–‡ç”Ÿæˆ
â”œâ”€â”€ rag_inference.py               # æ¨¡å‹æ¨ç†
â”œâ”€â”€ attention_analysis.py          # æ³¨æ„åŠ›åˆ†æ
â”œâ”€â”€ rag_result_analysis.py         # ç»“æœåˆ†æä¸å¯è§†åŒ–
â”‚
â”œâ”€â”€ rag_contexts/                  # ç”Ÿæˆçš„ä¸Šä¸‹æ–‡æ•°æ®
â”‚   â”œâ”€â”€ rag_bm25_1024tokens.jsonl
â”‚   â”œâ”€â”€ rag_bm25_2048tokens.jsonl
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ rag_jaccard_1024tokens.jsonl
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ metadata_*.json
â”‚
â”œâ”€â”€ rag_inference_results/         # æ¨ç†ç»“æœ
â”‚   â”œâ”€â”€ results_bm25_1024tokens.jsonl
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ inference_summary_*.json
â”‚
â”œâ”€â”€ attention_data/                # æ³¨æ„åŠ›æ•°æ®
â”‚   â””â”€â”€ attention_*.json
â”‚
â”œâ”€â”€ attention_analysis_output/     # æ³¨æ„åŠ›åˆ†æç»“æœ
â”‚   â”œâ”€â”€ attention_entropy_*.png
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ rag_analysis_output/           # æœ€ç»ˆåˆ†æç»“æœ
    â”œâ”€â”€ comprehensive_analysis.png # ç»¼åˆå¤§å›¾
    â”œâ”€â”€ pass1_bm25.png             # å°å›¾
    â”œâ”€â”€ pass1_jaccard.png
    â”œâ”€â”€ method_comparison.png
    â””â”€â”€ ...
```

## ğŸš€ å®éªŒæµç¨‹

### ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆç¨€ç–æ£€ç´¢ä¸Šä¸‹æ–‡

åœ¨**æœ¬åœ°æˆ–æœ‰ repos ç›®å½•çš„ç¯å¢ƒ**æ‰§è¡Œï¼š

```bash
# BM25 æ–¹æ³•
python sparse_retrieval_context.py \
    --method bm25 \
    --output ./rag_contexts \
    --dataset home/travis/builds/CoderEval4Python.json \
    --repos home/travis/builds/repos \
    --context-lengths 1024 2048 4096 8192 16384 32768 65536 131072 196608

# Jaccard æ–¹æ³•
python sparse_retrieval_context.py \
    --method jaccard \
    --output ./rag_contexts \
    --dataset home/travis/builds/CoderEval4Python.json \
    --repos home/travis/builds/repos \
    --context-lengths 1024 2048 4096 8192 16384 32768 65536 131072 196608
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `rag_contexts/rag_bm25_*tokens.jsonl`
- `rag_contexts/rag_jaccard_*tokens.jsonl`
- `rag_contexts/metadata_*.json`

### ç¬¬äºŒæ­¥ï¼šæ¨¡å‹æ¨ç†

æ”¯æŒä¸‰ç§æ¨ç†åç«¯ï¼š**vLLMï¼ˆæ¨èï¼‰**ã€Transformersã€API

#### æ–¹å¼ä¸€ï¼švLLM æ¨ç†ï¼ˆæ¨èï¼Œé«˜æ•ˆï¼‰

```bash
# BM25 ä¸Šä¸‹æ–‡æ¨ç†
python rag_inference.py \
    --input ./rag_contexts \
    --output ./rag_inference_results \
    --method bm25 \
    --backend vllm \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --tensor-parallel-size 1 \
    --gpu-memory-utilization 0.9 \
    --batch-size 8 \
    --all-lengths \
    --num-samples 10

# Jaccard ä¸Šä¸‹æ–‡æ¨ç†
python rag_inference.py \
    --input ./rag_contexts \
    --output ./rag_inference_results \
    --method jaccard \
    --backend vllm \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --all-lengths \
    --num-samples 10
```

**vLLM ç‰¹å®šå‚æ•°**ï¼š
| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--tensor-parallel-size` | GPU å¹¶è¡Œæ•° | 1 |
| `--gpu-memory-utilization` | GPU å†…å­˜ä½¿ç”¨ç‡ | 0.9 |
| `--max-model-len` | æ¨¡å‹æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ | è‡ªåŠ¨ |
| `--batch-size` | æ‰¹å¤„ç†å¤§å° | 8 |

#### æ–¹å¼äºŒï¼šTransformers æ¨ç†

```bash
python rag_inference.py \
    --input ./rag_contexts \
    --method bm25 \
    --backend transformers \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --all-lengths \
    --save-attention  # å¯é€‰ï¼šä¿å­˜æ³¨æ„åŠ›æ•°æ®
```

#### æ–¹å¼ä¸‰ï¼šAPI æ¨ç†ï¼ˆvLLM æœåŠ¡å™¨æˆ– OpenAI APIï¼‰

é¦–å…ˆå¯åŠ¨ vLLM æœåŠ¡å™¨ï¼š
```bash
python -m vllm.entrypoints.openai.api_server \
    --model /path/to/Qwen3-4B-Instruct-2507 \
    --port 8000
```

ç„¶åè¿è¡Œæ¨ç†ï¼š
```bash
python rag_inference.py \
    --input ./rag_contexts \
    --method bm25 \
    --backend api \
    --api-url http://localhost:8000/v1 \
    --model-name Qwen3-4B-Instruct-2507 \
    --all-lengths
```

### ç¬¬ä¸‰æ­¥ï¼šæ³¨æ„åŠ›åˆ†æï¼ˆå¯é€‰ï¼‰

åˆ†ææ¨¡å‹å¯¹ä¸åŒä¸Šä¸‹æ–‡åŒºåŸŸçš„æ³¨æ„åŠ›åˆ†å¸ƒï¼š

```bash
python attention_analysis.py \
    --attention-dir ./attention_data \
    --rag-dir ./rag_contexts \
    --dataset home/travis/builds/CoderEval4Python.json \
    --output ./attention_analysis_output \
    --method bm25 \
    --dpi 400
```

**è¾“å‡ºå›¾è¡¨**ï¼š
- `attention_entropy_*.png` - æ³¨æ„åŠ›ç†µéšä¸Šä¸‹æ–‡é•¿åº¦å˜åŒ–
- `attention_distribution_*.png` - æ³¨æ„åŠ›åœ¨ä¸åŒåŒºåŸŸçš„åˆ†å¸ƒ
- `oracle_relevance_*.png` - æ£€ç´¢å†…å®¹ä¸ oracle çš„ç›¸å…³æ€§
- `attention_summary_*.png` - ç»¼åˆåˆ†æå›¾

### ç¬¬å››æ­¥ï¼šç»“æœåˆ†æä¸å¯è§†åŒ–

```bash
python rag_result_analysis.py \
    --results-dir ./rag_inference_results \
    --rag-dir ./rag_contexts \
    --dataset home/travis/builds/CoderEval4Python.json \
    --output ./rag_analysis_output \
    --methods bm25 jaccard \
    --dpi 400
```

## ğŸ“Š è¾“å‡ºå›¾è¡¨è¯´æ˜

### ç»¼åˆå¤§å›¾ (`comprehensive_analysis.png`)

åŒ…å« 6 ä¸ªå­å›¾ï¼š

| å­å›¾ | å†…å®¹ |
|------|------|
| (a) | BM25 vs Jaccard pass@1 æŸ±çŠ¶å›¾å¯¹æ¯” |
| (b) | pass@k è¶‹åŠ¿æŠ˜çº¿å›¾ |
| (c) | BM25 è¯¦ç»† pass@1/5/10 |
| (d) | Jaccard è¯¦ç»† pass@1/5/10 |
| (e) | æ€§èƒ½çƒ­åŠ›å›¾ |
| (f) | æ–¹æ³•é—´å·®å¼‚å¯¹æ¯” |

### å°å›¾

| æ–‡ä»¶å | å†…å®¹ |
|--------|------|
| `pass1_bm25.png` | BM25 pass@1 æŠ˜çº¿å›¾ |
| `pass1_jaccard.png` | Jaccard pass@1 æŠ˜çº¿å›¾ |
| `pass_k_bm25.png` | BM25 pass@1/5/10 å¯¹æ¯” |
| `pass_k_jaccard.png` | Jaccard pass@1/5/10 å¯¹æ¯” |
| `method_comparison.png` | æ–¹æ³•å¯¹æ¯”æŸ±çŠ¶å›¾ |
| `trend_comparison.png` | è¶‹åŠ¿å¯¹æ¯”æŠ˜çº¿å›¾ |
| `context_*.png` | å„ä¸Šä¸‹æ–‡é•¿åº¦çš„è¯¦ç»†å¯¹æ¯” |

## âš™ï¸ å‚æ•°è¯´æ˜

### sparse_retrieval_context.py

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--method` | æ£€ç´¢æ–¹æ³• (bm25/jaccard) | bm25 |
| `--output` | è¾“å‡ºç›®å½• | ./rag_contexts |
| `--context-lengths` | ç›®æ ‡ä¸Šä¸‹æ–‡é•¿åº¦åˆ—è¡¨ | 1024 - 196608 |

### rag_inference.py

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--method` | æ£€ç´¢æ–¹æ³• | bm25 |
| `--all-lengths` | å¤„ç†æ‰€æœ‰é•¿åº¦ | false |
| `--num-samples` | æ¯ä»»åŠ¡ç”Ÿæˆä»£ç æ•° | 10 |
| `--save-attention` | ä¿å­˜æ³¨æ„åŠ› | false |
| `--temperature` | ç”Ÿæˆæ¸©åº¦ | 0.2 |

### rag_result_analysis.py

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--methods` | è¦åˆ†æçš„æ–¹æ³• | bm25 jaccard |
| `--dpi` | å›¾ç‰‡åˆ†è¾¨ç‡ | 400 |
| `--skip-analysis` | è·³è¿‡åˆ†æç›´æ¥ç”»å›¾ | false |

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

### Pass@k

ä½¿ç”¨ HumanEval è®ºæ–‡ä¸­çš„æ— åä¼°è®¡å…¬å¼ï¼š

$$\text{pass@}k = \mathbb{E}_{\text{Problems}} \left[ 1 - \frac{\binom{n-c}{k}}{\binom{n}{k}} \right]$$

å…¶ä¸­ï¼š
- $n$ = æ¯ä¸ªä»»åŠ¡ç”Ÿæˆçš„å€™é€‰ä»£ç æ•°é‡
- $c$ = é€šè¿‡æµ‹è¯•çš„ä»£ç æ•°é‡
- $k$ = é€‰å–çš„å€™é€‰æ•°

### æ³¨æ„åŠ›åˆ†ææŒ‡æ ‡

- **Attention Entropy**ï¼šè¡¡é‡æ³¨æ„åŠ›åˆ†å¸ƒçš„åˆ†æ•£ç¨‹åº¦
- **Region Distribution**ï¼šæ³¨æ„åŠ›åœ¨æ£€ç´¢å†…å®¹/ç›®æ ‡å‡½æ•°åŒºåŸŸçš„åˆ†å¸ƒ
- **Oracle Relevance**ï¼šæ£€ç´¢å†…å®¹ä¸æ ‡å‡†ç­”æ¡ˆç›¸å…³ä»£ç çš„é‡å åº¦

## ğŸ”§ ä¾èµ–å®‰è£…

```bash
# åŸºç¡€ä¾èµ–
pip install numpy matplotlib requests

# vLLM åç«¯ï¼ˆæ¨èï¼‰
pip install vllm

# Transformers åç«¯
pip install transformers torch
```

**vLLM å®‰è£…æ³¨æ„äº‹é¡¹**ï¼š
- éœ€è¦ CUDA 11.8+ æˆ– 12.x
- æ¨è Python 3.9+
- è¯¦è§ [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/en/latest/getting_started/installation.html)

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ä¸Šä¸‹æ–‡ç”Ÿæˆ**éœ€è¦å®Œæ•´çš„ CoderEval repos ç›®å½•
2. **æ¨¡å‹æ¨ç†**éœ€è¦ GPU ç¯å¢ƒï¼ˆæ¨èï¼‰
3. **æ³¨æ„åŠ›åˆ†æ**éœ€è¦åœ¨æ¨ç†æ—¶å¼€å¯ `--save-attention`
4. ç¡®ä¿ `--num-samples` å‚æ•°åœ¨æ‰€æœ‰æ­¥éª¤ä¸­ä¿æŒä¸€è‡´

## ğŸ”„ å¿«é€Ÿå¼€å§‹ï¼ˆå®Œæ•´æµç¨‹ï¼‰

```bash
# 1. ç”Ÿæˆä¸Šä¸‹æ–‡ï¼ˆæœ¬åœ°æ‰§è¡Œï¼‰
python sparse_retrieval_context.py --method bm25 --output ./rag_contexts
python sparse_retrieval_context.py --method jaccard --output ./rag_contexts

# 2. ä½¿ç”¨ vLLM æ¨ç†ï¼ˆäº‘ç«¯/GPU ç¯å¢ƒï¼‰
python rag_inference.py \
    --method bm25 \
    --backend vllm \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --tensor-parallel-size 1 \
    --batch-size 8 \
    --all-lengths

python rag_inference.py \
    --method jaccard \
    --backend vllm \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --all-lengths

# 3. åˆ†æä¸å¯è§†åŒ–
python rag_result_analysis.py --methods bm25 jaccard --dpi 400
```

### å• GPU æ¨ç†ç¤ºä¾‹

```bash
# 192k é•¿ä¸Šä¸‹æ–‡å¯èƒ½éœ€è¦æ›´å¤§æ˜¾å­˜
python rag_inference.py \
    --method bm25 \
    --backend vllm \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --tensor-parallel-size 1 \
    --gpu-memory-utilization 0.95 \
    --max-model-len 200000 \
    --context-length 196608
```

### å¤š GPU æ¨ç†ç¤ºä¾‹

```bash
# ä½¿ç”¨ 4 å¼  GPU è¿›è¡Œ tensor å¹¶è¡Œ
python rag_inference.py \
    --method bm25 \
    --backend vllm \
    --model-path /path/to/Qwen3-4B-Instruct-2507 \
    --tensor-parallel-size 4 \
    --batch-size 16 \
    --all-lengths
```

## ğŸ“Š é¢„æœŸç»“æœ

å®éªŒåº”è¯¥èƒ½å¤Ÿå±•ç¤ºï¼š

1. **ä¸Šä¸‹æ–‡é•¿åº¦å½±å“**ï¼šéšç€ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ ï¼Œpass@k çš„å˜åŒ–è¶‹åŠ¿
2. **æ£€ç´¢æ–¹æ³•å¯¹æ¯”**ï¼šBM25 vs Jaccard åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½å·®å¼‚
3. **æ³¨æ„åŠ›åˆ†å¸ƒ**ï¼šæ¨¡å‹æ˜¯å¦æ­£ç¡®å…³æ³¨äº†æ£€ç´¢åˆ°çš„ç›¸å…³ä»£ç 
4. **æœ€ä¼˜é…ç½®**ï¼šç¡®å®šæœ€ä½³çš„ä¸Šä¸‹æ–‡é•¿åº¦å’Œæ£€ç´¢æ–¹æ³•ç»„åˆ

